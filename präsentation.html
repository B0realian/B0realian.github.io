<!DOCTYPE html>
<html lang="en">
  	<head>
    	<meta charset="utf-8">
    	<link href='https://fonts.googleapis.com/css?family=Montserrat:400,700' rel='stylesheet'>
    	<link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet'>
    	<title>My lovely internship</title>
    	<style>
    		html, body {
	    		background-color: #030c1b;
	    		height: 100%;
	    		margin: 0;
	    		font-family: 'Lato';
	    		font-size: 21px;
	    	}

	    	h1 {
				font-family: 'Montserrat';
	    		font-size: 50px;
	    	}

	    	.std {
	    		height: 800%;
	    		width: 50%;
	    		margin: auto;
	    		background-color: #04122b;
	      		color: white;
	      		text-align: center;	      		
	    	}

	    	p {
	    		width: 70%;
	    		margin: auto;
	    	}
	    </style>
  	</head>

	<body>
		<div class="std">
			<h1>INTERNING WITH</h1>
			<img src="Nornware.png" alt="Pic went Oops!" style="width: 600px; height: 110px;">
			<p><br>Most of you in GP23 know Nornware from the bonus lectures we received on shaders at the start of our second year. I know a lot of us felt like it was a bit too much to take in and understand at that point but I'm sure everyone else was equally awed with how much can be done visually by just fiddling with numbers in shaders. Naturally, my instinct was to think that this is what I should add to my toolkit! What followed was not quite what I had expected however.
			<br><br>
			Nornware is a single developer - Johannes Norneby - who was lead on Massive's first title Ground Control. He has also been at DiCE and been consulted by numerous other studios, as well as evaluated a John Romero project for investors. He has applied OOP about as far as it goes and then embraced low level programming as a result. After seven years in early access, his game Space Beast Terror Fright received its final release a couple of years ago, built by him from the ground up.
			<br><br></p>
			<img src="sbtf.png" alt="Pic went Oops!" style="width: 600px; height: 338px;">
			<p><br>So, what could I help one of the most senior developers in the country with? I think Johannes was a little dubious about my potential but he hid it well and asked me to create a terrain making tool from scratch, possibly using OpenGL as a renderer, adding that if I failed miserably that was fine as long as I learnt something. After spending a couple of weeks improving my standard C++ (I had only programmed C++ within UE up to this point) I started to learn the OpenGL API and soon had a prototype for a terrain maker up and running. However, I decided to take a shortcut when I realised there was a bumpmap with every megascans file, so instead of loading a mesh, I used the bumpmap as heightmap and created a mesh. Since the textures in megascans are high resolution, the file was 4K and produced a mesh with a whopping 35 million triangles.
			<br><br>
			While I thought I had been ever so clever, this wasn't what Johannes had asked for and it turned out to have no use for him. So, I quickly abandoned the project and started a new one in which I adhered to the specification exactly. At any rate, I <i>did</i> find and look at an example of using heightmaps but decided to go my own route. I also decided to use an average of rgb brightness to decide height, meaning <i>any</i> texture works quite well.
			<br><br></p>
			<img src="terraform.png" alt="Pic went Oops!" style="width: 700px; height: 600px;">
			<p><br>Program in action!
			<br><br>
			<img src="img/portfolio/BumpLand/teddy_sm.png" alt="Pic went Oops!" style="width: 512px; height: 512px;">
			<img src="img/portfolio/BumpLand/BL_teddy.gif" alt="Pic went Oops!" style="width: 426px; height: 240px;">
			<p><br>It was time to make the specified terrain creator. I repurposed some of the code from the previous attempt and decided to use the very excellent STB lib by Sean Barrett because there was no way I was going to spend all the time to write my own loaders for .png or .jpg and I really couldn’t expect the user to convert all textures to .tga. I did, however, write my own loaders for .obj, .fbx (admittedly using the fbx sdk) and .gltf meshes. To parse the json “header” of .gltf I included the also excellent json.hpp by Niels Lohmann. Why? Partly because I knew I could and it would be a good learning experience and partly because I wanted the added portability: smaller file size and fewer dependencies. This was also something that I felt a low level wizard like Johno respected and encouraged.
			<br><br>
			Creating an array of vertices from mesh data is typically straight forward. However, I did groan when I realised that the gltf-format supported data embedded as a base64 encoded string. Incidentally, this is why you should only use .gltfs with embedded data if running webGL (or another web graphics API): load time and performance takes a definite hit from decoding the data. However daunting I initially found the prospect of writing a decoder, I was surprised when my first attempt just worked. Partly, this stemmed from not having copied someone else’s decoder: I had to look up what base64 entailed which detailed some of the necessary steps (such as the base64 table) but otherwise I just wrote what I figured should be how it works.
			<br><br></p>
			<img src="base64.png" alt="Pic went Oops!" style="width: 800px; height: 860px;">
			<p><br>Hands up if you have no idea how to write code for taking and saving screenshots. I had no idea myself. But OpenGL provides! So capturing images turned out to be the simplest part of the process:
			<br><br>
			glReadPixels(0, 0, in_width, in_height, GL_RGB, GL_FLOAT, capturedColor);
			<br>
			glReadPixels(0, 0, in_width, in_height, GL_DEPTH_COMPONENT, GL_FLOAT, capturedDepth);
			<br><br>
			STB does not have a save feature so I was left with writing my own files. For colour, I had already written a .tga loader and saver so implementing that was easy. Trouble was saving 16-bit grayscale, which is not supported by most colour-formats. Enter Portable GrayMap! It saves raw in text so file size is ludicrous, but it works and saved me the trouble of trying to understand .tiff.
			<br><br>
			Finished! Well, no. The program did everything that was asked for but it <i>was</i> a very clunky user experience. Hence, more time was then spent adding features than it took to create the prototype, which should have come as no surprise. Basically, I needed an interface: text! So a google search gave me
			<br><br>
			<i>"In the early days, rendering text involved selecting a font (or create one yourself) you'd like for your application and extracting all relevant characters out of this font to place them within a single large texture. Such a texture, that we call a bitmap font, contains all character symbols we want to use in predefined regions of the texture. These character symbols of the font are known as glyphs. Each glyph has a specific region of texture coordinates associated with them. Whenever you want to render a character, you select the corresponding glyph by rendering this section of the bitmap font to a 2D quad."</i>
			<br><br>
			and I was like: I can do that! So I made my own bitmap using a font called Cascadia (you <i>really</i> want a monospaced font for this)
			<br><br></p>
			<img src="img/portfolio/M2I/bmtxt.png" alt="Pic went Oops!" style="width: 640px; height: 108px;">
			<p><br><br>
			then created a struct for the uv-coordinates and a map (that’s a dictionary for you C# coders out there) with the corresponding chars
			<br><br></p>
			<img src="cascadiamap.png" alt="Pic went Oops!" style="width: 711px; height: 490px;">
			<p><br><br>
			so that I could reassemble uv coordinates for the vertices in runtime.
			<br><br></p>
			<img src="textverts.png" alt="Pic went Oops!" style="width: 594px; height: 834px;">
			<p><br><br>
			Et voilá!
			<br><br></p>
			<img src="img/portfolio/m2i.png" alt="Pic went Oops!" style="width: 900px; height: 650px;">
			<p><br><br>
			But there was one problem: the font imagefile had to accompany the program, i.e. I had created a dependency. Wouldn't it be a lot nicer if I could inline the image? The reason you typically don't is because each pixel is 32 bytes so even small images inflate your program's size a lot. But I was only really interested in whether the pixel's alpha was 1 or 0, meaning I could fit a pixel in a bit, which means my image would be 256 times smaller. So I wrote a small program that fit 8 pixels per byte and wrote each byte cast as an int followed by a comma to a text file. So now I had all the data in the shape of an array and could copy it into my header.
			<br><br></p>
			<img src="bits.png" alt="Pic went Oops!" style="width: 517px; height: 417px;">
			<p><br><br>
			And this little operation led to what is possibly my proudest moment in Yrgo:
			<br><br></p>
			<img src="praise.png" alt="Pic went Oops!" style="width: 443px; height: 124px;">
			<p><br><br>
			All in all, it took me about three months to learn and write the two terrain-making programs, where roughly one month was spent on learning the OpenGL basics and writing the first program.
			<br><br></p>
		</div>
	</body>
</html> 